{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Heirarchical.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2Ot+vN2Csk+t49B0Qw3hl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"vUDoWFkSFuBv","executionInfo":{"status":"ok","timestamp":1638212682545,"user_tz":-330,"elapsed":8322,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}}},"source":["# from transformers import BertTokenizer, BertModel\n","import nltk\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HeuCygwnw2iM","executionInfo":{"status":"ok","timestamp":1638212683245,"user_tz":-330,"elapsed":729,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"d771ebc2-ae8e-4bd1-ef4e-0590b136d5f7"},"source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GlScrqSGyD4","executionInfo":{"status":"ok","timestamp":1638212711491,"user_tz":-330,"elapsed":28254,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"6c449354-d25f-410e-f2d9-597d91ead94c"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"QipE6J-BxlcJ","executionInfo":{"status":"ok","timestamp":1638212713282,"user_tz":-330,"elapsed":1796,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}}},"source":["\"/content/drive/MyDrive/DLNLP project/socialnetwork.paraphrases.train.examples\"\n","\"/content/drive/MyDrive/DLNLP project/socialnetwork.paraphrases.test.examples\"\n","\n","with open('/content/drive/MyDrive/DLNLP project/publications.paraphrases.train.examples','r') as f:\n","  examples = f.readlines()\n","  lines = [e.strip().split('\\n') for e in examples]\n","\n","\n","utterance = []\n","original = []\n","\n","for line in lines:\n","  if line[0].find('(utterance') == 0:\n","    utterance.append(line[0][12:-2])\n","  if line[0].find('(original') == 0:\n","    original.append(line[0][11:-2])\n","\n","\n","import pandas as pd\n","\n","df = pd.DataFrame({'utterance':utterance, 'original':original})\n","\n","df['utterance'] = df['utterance'].apply(lambda x : ' '.join(x.split()))\n","df['original'] = df['original'].apply(lambda x : ' '.join(x.split()))\n","df.to_csv('train_data.csv',index=False)\n","\n","with open('/content/drive/MyDrive/DLNLP project/publications.paraphrases.test.examples','r') as f:\n","  examples = f.readlines()\n","  lines = [e.strip().split('\\n') for e in examples]\n","\n","\n","utterance = []\n","original = []\n","\n","for line in lines:\n","  if line[0].find('(utterance') == 0:\n","    utterance.append(line[0][12:-2])\n","  if line[0].find('(original') == 0:\n","    original.append(line[0][11:-2])\n","\n","df = pd.DataFrame({'utterance':utterance, 'original':original})\n","\n","df['utterance'] = df['utterance'].apply(lambda x : ' '.join(x.split()))\n","df['original'] = df['original'].apply(lambda x : ' '.join(x.split()))\n","df.to_csv('test_data.csv',index=False)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8E--gJOIG9m3","executionInfo":{"status":"ok","timestamp":1638212713283,"user_tz":-330,"elapsed":45,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}}},"source":["train_df = pd.read_csv(\"train_data.csv\")\n","test_df = pd.read_csv(\"test_data.csv\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"_jhXObKiHDsP","executionInfo":{"status":"ok","timestamp":1638212713284,"user_tz":-330,"elapsed":46,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"c7d90315-28ae-49ef-ac53-0c74ba930a00"},"source":["train_df.tail()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>utterance</th>\n","      <th>original</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>635</th>\n","      <td>what article cites the fewest articles</td>\n","      <td>article that cites the least number of article</td>\n","    </tr>\n","    <tr>\n","      <th>636</th>\n","      <td>what is an article that does not cite multivar...</td>\n","      <td>article that multivariate data analysis not cites</td>\n","    </tr>\n","    <tr>\n","      <th>637</th>\n","      <td>find an article with no more than two venues</td>\n","      <td>article that has at most two venue</td>\n","    </tr>\n","    <tr>\n","      <th>638</th>\n","      <td>name an article found in two venues</td>\n","      <td>article that has two venue</td>\n","    </tr>\n","    <tr>\n","      <th>639</th>\n","      <td>what 2004 article was cited by multivariate da...</td>\n","      <td>article whose publication date is 2004 and tha...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             utterance                                           original\n","635             what article cites the fewest articles     article that cites the least number of article\n","636  what is an article that does not cite multivar...  article that multivariate data analysis not cites\n","637       find an article with no more than two venues                 article that has at most two venue\n","638                name an article found in two venues                         article that has two venue\n","639  what 2004 article was cited by multivariate da...  article whose publication date is 2004 and tha..."]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"M2lQnA34BlPm"},"source":["CD cardinal digit                                                               \n","DT determiner                                                             \n","JJ adjective ‘big’                               \n","JJR adjective 'bigger' comparative                                                                                                     \n","JJS adjective, superlative   'biggest'                                                        \n","NN noun, singular ‘desk’                                                                                                \n","NNS noun plural ‘desks’                                                                                  \n","NNP proper noun, singular ‘Harrison’                                                            \n","NNPS proper noun, plural‘Americans’                                                                                                 \n","RB adverb very, silently,                             \n","RBR adverb, comparative 'better'                                                                        \n","RBS adverb, superlative 'best'"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhYwm7U2zJ6v","executionInfo":{"status":"ok","timestamp":1638212713285,"user_tz":-330,"elapsed":45,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"3173103b-6167-4459-d72f-a06009b3fb2e"},"source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.tokenize import PunktSentenceTokenizer\n","stop_words = set(stopwords.words('english'))\n","  \n","\n","sentence_tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()\n","\n","dict_NP_count_chunk = {}\n","\n","grammar = r\"NP: {<DT>?<JJ.*|RB.*|CD>*<NN.*>+}\"\n","# grammar = r\"\"\"NP: {<DT|PP\\$>?<JJ>*<NN>}{<NNP>+}\"\"\"\n","\n","Parser = nltk.RegexpParser(grammar)\n","unique_NP = []\n","NP_list = []\n","\n","for sentence in train_df['original'].tolist() +test_df['original'].tolist():\n","    \n","    wordsList = sentence_tokenizer.tokenize(sentence)[0].split()\n","\n","    tagged = nltk.pos_tag(wordsList)\n","    # print(tagged)\n","    pos_list = str(Parser.parse(tagged)).split()\n","    # print(pos_list)\n","\n","    # count = 0\n","    temp_list = []\n","    temp_set =  set()\n","\n","    while True:\n","      try:\n","        id = pos_list.index('(NP')\n","        # count += 1\n","        tok = []\n","        for dummy in pos_list[id+1:]:\n","          dummy = dummy.split('/')\n","          tok.append(dummy[0])\n","\n","          if len(dummy[1]) >= 3 and dummy[1][-1] == ')':\n","            break\n","\n","        pos_list = pos_list[id+1:]\n","        unique_NP.append(' '.join(tok))\n","\n","        if ' '.join(tok) not in temp_set:\n","          temp_list.append(' '.join(tok))\n","          temp_set.add(' '.join(tok))\n","      except:\n","        break\n","\n","    try:\n","      dict_NP_count_chunk[len(temp_list)].append((sentence,temp_list))\n","    except:\n","      dict_NP_count_chunk[len(temp_list)] = []\n","      dict_NP_count_chunk[len(temp_list)].append((sentence,temp_list))\n","\n","    NP_list.append(temp_list)\n","\n","# print(dict_NP_count_chunk)\n","unique_NP = set(unique_NP)\n","print(unique_NP)\n","# train_df['NP_list'] = NP_list"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'data analysis', 'publication date', 'number', 'most two article cites', 'computational linguistics', 'venue', 'multivariate data analysis', 'author', 'two author', 'two venue', 'an award cites', 'least publication date', 'most publication date', 'least two article cites', 'the most number', '2004 cites', 'efron cites', 'least two article', 'article', 'two article cites', 'least two author', 'cites', 'that multivariate data analysis cites', 'most two venue', 'person', 'multivariate data analysis cites', 'an award', 'the least number', 'article cites', 'least two venue', 'the smallest publication date', 'the largest publication date', 'statistics cites', 'annals', 'most two author', 'most two article', 'two article', 'statistics'}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"-yD0NCtU0djo","executionInfo":{"status":"ok","timestamp":1638212713286,"user_tz":-330,"elapsed":43,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"118e1d0e-d854-4160-fef9-a247f3e6bcdb"},"source":["train_df.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>utterance</th>\n","      <th>original</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>article with the largest amount of authors</td>\n","      <td>article that has the most number of author</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>article citing article published in annals of ...</td>\n","      <td>article that article whose venue is annals of ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>what article from 2004 cites multivariate data...</td>\n","      <td>article whose publication date is 2004 and tha...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>find an article published in 2004</td>\n","      <td>article whose publication date is 2004</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>articles that have a publication date close to...</td>\n","      <td>article whose publication date is at most publ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           utterance                                           original\n","0         article with the largest amount of authors         article that has the most number of author\n","1  article citing article published in annals of ...  article that article whose venue is annals of ...\n","2  what article from 2004 cites multivariate data...  article whose publication date is 2004 and tha...\n","3                  find an article published in 2004             article whose publication date is 2004\n","4  articles that have a publication date close to...  article whose publication date is at most publ..."]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_J0SBKt17Kf","executionInfo":{"status":"ok","timestamp":1638212713287,"user_tz":-330,"elapsed":43,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"41ff531e-d70f-4cce-d102-15b56a0da37a"},"source":["print(f\"max number of Noun phrases a sentence has : {len(dict_NP_count_chunk.items())}\")\n","print(f\"Length of noun phrases : {dict_NP_count_chunk.keys()}\")\n","print(f\"#Unique Noun phrases in the Dataset : {len(unique_NP)}\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["max number of Noun phrases a sentence has : 6\n","Length of noun phrases : dict_keys([3, 4, 2, 5, 6, 0])\n","#Unique Noun phrases in the Dataset : 38\n"]}]},{"cell_type":"code","metadata":{"id":"JHeBy2cQsW8h","executionInfo":{"status":"ok","timestamp":1638212713288,"user_tz":-330,"elapsed":42,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}}},"source":["# dict_NP_count_chunk[1]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"UZLf9-z9kZyV","executionInfo":{"status":"ok","timestamp":1638212713288,"user_tz":-330,"elapsed":41,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"e4241e70-0eac-4537-e6d9-bc94eb9b32d8"},"source":["test_df.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>utterance</th>\n","      <th>original</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what article has the most number of articles c...</td>\n","      <td>article that the most number of article cites</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>person who has not published article in multiv...</td>\n","      <td>person that is not author of multivariate data...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>what person is not the author of multivariate ...</td>\n","      <td>person that is not author of multivariate data...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>article cited by two articles</td>\n","      <td>article that two article cites</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>articles that do not cite multivariate data an...</td>\n","      <td>article that not cites multivariate data analysis</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           utterance                                           original\n","0  what article has the most number of articles c...      article that the most number of article cites\n","1  person who has not published article in multiv...  person that is not author of multivariate data...\n","2  what person is not the author of multivariate ...  person that is not author of multivariate data...\n","3                      article cited by two articles                     article that two article cites\n","4  articles that do not cite multivariate data an...  article that not cites multivariate data analysis"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"fahtbp4jw948","executionInfo":{"status":"ok","timestamp":1638212713289,"user_tz":-330,"elapsed":41,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}}},"source":["test_NP_list = []\n","\n","for sentence in test_df['utterance']:\n","    \n","    wordsList = sentence_tokenizer.tokenize(sentence)[0].split()\n","\n","    tagged = nltk.pos_tag(wordsList)\n","    # print(tagged)\n","    pos_list = str(Parser.parse(tagged)).split()\n","    # print(pos_list)\n","\n","    # count = 0\n","    temp_list = []\n","    temp_set = set()\n","\n","    while True:\n","      try:\n","        id = pos_list.index('(NP')\n","        # count += 1\n","        tok = []\n","        for dummy in pos_list[id+1:]:\n","          dummy = dummy.split('/')\n","          tok.append(dummy[0])\n","          if len(dummy[1]) >= 3 and dummy[1][-1] == ')':\n","            break\n","        pos_list = pos_list[id+1:]\n","        \n","        if ' '.join(tok) not in temp_set:\n","          temp_list.append(' '.join(tok))\n","          temp_set.add(' '.join(tok))\n","      except:\n","        break\n","\n","    test_NP_list.append(temp_list)\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"OQ_mPS7Gw96u","executionInfo":{"status":"ok","timestamp":1638212713290,"user_tz":-330,"elapsed":42,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"542463d5-4d2a-41a4-f99a-d63eecf40002"},"source":["test_df['NP_utterance_list'] = test_NP_list\n","test_df.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>utterance</th>\n","      <th>original</th>\n","      <th>NP_utterance_list</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what article has the most number of articles c...</td>\n","      <td>article that the most number of article cites</td>\n","      <td>[article, the most number, articles]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>person who has not published article in multiv...</td>\n","      <td>person that is not author of multivariate data...</td>\n","      <td>[person, article, multivariate data analysis]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>what person is not the author of multivariate ...</td>\n","      <td>person that is not author of multivariate data...</td>\n","      <td>[person, the author, multivariate data analysis]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>article cited by two articles</td>\n","      <td>article that two article cites</td>\n","      <td>[article, two articles]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>articles that do not cite multivariate data an...</td>\n","      <td>article that not cites multivariate data analysis</td>\n","      <td>[articles, multivariate data analysis]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           utterance  ...                                 NP_utterance_list\n","0  what article has the most number of articles c...  ...              [article, the most number, articles]\n","1  person who has not published article in multiv...  ...     [person, article, multivariate data analysis]\n","2  what person is not the author of multivariate ...  ...  [person, the author, multivariate data analysis]\n","3                      article cited by two articles  ...                           [article, two articles]\n","4  articles that do not cite multivariate data an...  ...            [articles, multivariate data analysis]\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgbyE579w99X","executionInfo":{"status":"ok","timestamp":1638212713291,"user_tz":-330,"elapsed":41,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"699d01e8-9ea6-48b0-f0a2-2adaabbdd9de"},"source":["exact_match = []\n","\n","for  NP_list,target in zip(test_df['NP_utterance_list'].tolist(),test_df['original'].tolist()):\n","\n","\n","  # check alignment\n","  max_similarity = -1\n","  best_mapping = \"\"\n","  # similarity_score = -1\n","\n","  if len(NP_list) not in dict_NP_count_chunk.keys():\n","    continue\n","\n","  for sentence in dict_NP_count_chunk[len(NP_list)]:\n","    similarity_score = 0\n","    # print(NP_list,sentence[1])\n","\n","    assert len(NP_list) == len(sentence[1])\n","\n","    for x,y in zip(NP_list,sentence[1]):\n","      # print(f\"{x},{y}\")\n","      similarity_score += int(x == y)\n","    \n","      if max_similarity < similarity_score:\n","        best_mapping,max_similarity = sentence[0],similarity_score\n","  \n","  if target == best_mapping:\n","    exact_match.append(f\"{best_mapping} ## {target} ## {max_similarity}\")\n","\n","print(exact_match[:5])"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['article that has the smallest publication date ## article that has the smallest publication date ## 2', 'article that has at most two author ## article that has at most two author ## 2', 'venue that is venue of less than two article ## venue that is venue of less than two article ## 1', 'article that cites the most number of article ## article that cites the most number of article ## 2', 'venue that is venue of less than two article ## venue that is venue of less than two article ## 2']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8B3WY0FEhH6","executionInfo":{"status":"ok","timestamp":1638212770178,"user_tz":-330,"elapsed":676,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"2b2b451b-64e2-4f49-d014-98383d9cac5c"},"source":["print(len(exact_match))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["48\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reybi1o3FQMS","executionInfo":{"status":"ok","timestamp":1638212713293,"user_tz":-330,"elapsed":38,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}},"outputId":"f22be448-3e88-4eee-a479-49598cb1a737"},"source":["print(len(test_df))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["161\n"]}]},{"cell_type":"code","metadata":{"id":"ec0C-VVguX5Q","executionInfo":{"status":"ok","timestamp":1638212713296,"user_tz":-330,"elapsed":28,"user":{"displayName":"Ritam Chattopadhyay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01007328510308016568"}}},"source":[""],"execution_count":20,"outputs":[]}]}